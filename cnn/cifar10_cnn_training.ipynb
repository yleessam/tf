{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yleessam/tf/blob/main/cifar10_cnn_training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#1. 구글 텐서플로 라이브러리 임포트\n",
        "CIFAR10 데이터셋은 컬러 이미지셋이므로 기존 neural network로는 분류가 쉽지 않다. 따라서 이미지 분류 전용의 CNN을 사용하려 한다. CNN 역시 tensorflow계열의 딥러닝 라이브러리이므로 필요한 파이썬 라이브러리를 임포트한다."
      ],
      "metadata": {
        "id": "PvBnv2ppIUHO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "SsSoK6ZNH7Pl"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.datasets import cifar10\n",
        "from sklearn.preprocessing import LabelBinarizer\n",
        "from tensorflow.keras.optimizers import SGD\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Conv2D\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.layers import Flatten\n",
        "from tensorflow.keras.layers import Activation\n",
        "from sklearn.metrics import classification_report"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#2. CIFAR10 데이터셋 다운로드\n",
        "CIFAR10 데이터셋은 이미지 딥러닝 교육에 많이 사용되는 데이터셋으로 구글의 파이썬 명령 하나로 서버에서 다운로드 받을 수 있다.    \n",
        "trainX는 트레이닝용 입력 이미지 데이터(비행기 이미지), trainY는 입력 이미지의 결과값 (비행기) 이다.\n",
        "\n",
        "이미지 사이즈는 32x32이다.\n",
        "\n",
        "trainX.shpae 명령으로 사이즈를 확인할 수 있다. testX, testY는 검증용 데이터셋 이다."
      ],
      "metadata": {
        "id": "z3s-NzBAI3PK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "((trainX, trainY), (testX, testY)) = cifar10.load_data()\n",
        "# 입력 데이터인 trainX 사이즈를 확인하기\n",
        "print(trainX.shape)\n",
        "# 실제 입력데이터 60000개 중 첫번째것의 실제 이미지 데이터를 확인하기\n",
        "print(trainX[0])\n",
        "# 실제 출력데이터 60000개 중 첫번째것을 확인하기\n",
        "print(trainY[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wDQIHQcHJHCg",
        "outputId": "ae62d64e-bdeb-459d-f2d1-3cd9489e03e5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170498071/170498071 [==============================] - 6s 0us/step\n",
            "(50000, 32, 32, 3)\n",
            "[[[ 59  62  63]\n",
            "  [ 43  46  45]\n",
            "  [ 50  48  43]\n",
            "  ...\n",
            "  [158 132 108]\n",
            "  [152 125 102]\n",
            "  [148 124 103]]\n",
            "\n",
            " [[ 16  20  20]\n",
            "  [  0   0   0]\n",
            "  [ 18   8   0]\n",
            "  ...\n",
            "  [123  88  55]\n",
            "  [119  83  50]\n",
            "  [122  87  57]]\n",
            "\n",
            " [[ 25  24  21]\n",
            "  [ 16   7   0]\n",
            "  [ 49  27   8]\n",
            "  ...\n",
            "  [118  84  50]\n",
            "  [120  84  50]\n",
            "  [109  73  42]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[208 170  96]\n",
            "  [201 153  34]\n",
            "  [198 161  26]\n",
            "  ...\n",
            "  [160 133  70]\n",
            "  [ 56  31   7]\n",
            "  [ 53  34  20]]\n",
            "\n",
            " [[180 139  96]\n",
            "  [173 123  42]\n",
            "  [186 144  30]\n",
            "  ...\n",
            "  [184 148  94]\n",
            "  [ 97  62  34]\n",
            "  [ 83  53  34]]\n",
            "\n",
            " [[177 144 116]\n",
            "  [168 129  94]\n",
            "  [179 142  87]\n",
            "  ...\n",
            "  [216 184 140]\n",
            "  [151 118  84]\n",
            "  [123  92  72]]]\n",
            "[6]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 데이터전처리\n",
        "\n",
        "**입력 이미지 데이터 노말라이징** <br>\n",
        "입력 이미지 데이터는 정수의 배열로 데이터가 구성되어 있다.   \n",
        "이 데이터는 0 ~ 255까지의 숫자이다.   \n",
        "이 숫자를 0 ~ 1사이의 값으로 변경하는 것이 텐서플로에서 처리하기 쉽다.\n",
        "\n",
        "노말라이징은 입력 이미지 데이터인 trainX, testX가 대상이다."
      ],
      "metadata": {
        "id": "H9Xa_jm4Kc6_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trainX = trainX.astype(\"float\")/255\n",
        "testX = testX.astype(\"float\")/255\n",
        "# trainX[0]의 정수 데이터들이 노말라이징 된 것을 확인한다.\n",
        "print(trainX[0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lu8CEj2fKx_0",
        "outputId": "dfaf1feb-661a-456e-8c86-f25ba9d751f8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[0.23137255 0.24313725 0.24705882]\n",
            "  [0.16862745 0.18039216 0.17647059]\n",
            "  [0.19607843 0.18823529 0.16862745]\n",
            "  ...\n",
            "  [0.61960784 0.51764706 0.42352941]\n",
            "  [0.59607843 0.49019608 0.4       ]\n",
            "  [0.58039216 0.48627451 0.40392157]]\n",
            "\n",
            " [[0.0627451  0.07843137 0.07843137]\n",
            "  [0.         0.         0.        ]\n",
            "  [0.07058824 0.03137255 0.        ]\n",
            "  ...\n",
            "  [0.48235294 0.34509804 0.21568627]\n",
            "  [0.46666667 0.3254902  0.19607843]\n",
            "  [0.47843137 0.34117647 0.22352941]]\n",
            "\n",
            " [[0.09803922 0.09411765 0.08235294]\n",
            "  [0.0627451  0.02745098 0.        ]\n",
            "  [0.19215686 0.10588235 0.03137255]\n",
            "  ...\n",
            "  [0.4627451  0.32941176 0.19607843]\n",
            "  [0.47058824 0.32941176 0.19607843]\n",
            "  [0.42745098 0.28627451 0.16470588]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[0.81568627 0.66666667 0.37647059]\n",
            "  [0.78823529 0.6        0.13333333]\n",
            "  [0.77647059 0.63137255 0.10196078]\n",
            "  ...\n",
            "  [0.62745098 0.52156863 0.2745098 ]\n",
            "  [0.21960784 0.12156863 0.02745098]\n",
            "  [0.20784314 0.13333333 0.07843137]]\n",
            "\n",
            " [[0.70588235 0.54509804 0.37647059]\n",
            "  [0.67843137 0.48235294 0.16470588]\n",
            "  [0.72941176 0.56470588 0.11764706]\n",
            "  ...\n",
            "  [0.72156863 0.58039216 0.36862745]\n",
            "  [0.38039216 0.24313725 0.13333333]\n",
            "  [0.3254902  0.20784314 0.13333333]]\n",
            "\n",
            " [[0.69411765 0.56470588 0.45490196]\n",
            "  [0.65882353 0.50588235 0.36862745]\n",
            "  [0.70196078 0.55686275 0.34117647]\n",
            "  ...\n",
            "  [0.84705882 0.72156863 0.54901961]\n",
            "  [0.59215686 0.4627451  0.32941176]\n",
            "  [0.48235294 0.36078431 0.28235294]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**출력 데이터셋 라벨 바이나리징** <br>\n",
        "CIFAR10 출력 데이터셋 즉 라벨값은 0 ~ 9사이의 정수이다.   \n",
        "이 정수를 바이너리 벡터화 하는 것이 라벨바이나리징인데 이것을 실행한다. <br>\n",
        "\n",
        "**10자리 행렬에서 3번째자리에 체크\n",
        "\n",
        "2 -> [0 0 1 0 0 0 0 0 0 0 0]"
      ],
      "metadata": {
        "id": "V9CSx4enMIDR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(trainY[0])\n",
        "\n",
        "lb = LabelBinarizer()\n",
        "\n",
        "trainY = lb.fit_transform(trainY)\n",
        "testY = lb.fit_transform(testY)\n",
        "\n",
        "print(trainY[0]) # 라벨바이나리징 전후를 비교하기"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IU4c7ajfM0cB",
        "outputId": "ced4013d-b3bd-44fa-90e3-b6bb1c5225f2"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[6]\n",
            "[0 0 0 0 0 0 1 0 0 0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**라벨 데이터의 숫자 맵핑** <br>\n",
        "CIFAR10 10개의 데이터의 이름을 숫자와 맵핑한다.    \n",
        "여기서는 참고로만 사용한다.\n",
        "\n",
        "실제 코드에는 사용하지 않는다.   "
      ],
      "metadata": {
        "id": "SyWWWq5ELu6A"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "labelNames = [\"airplane\", \"automobile\", \"bird\", \"cat\", \"deer\",\n",
        "\t\"dog\", \"frog\", \"horse\", \"ship\", \"truck\"]"
      ],
      "metadata": {
        "id": "lnKaSBIzM7f_"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 모델을 구성하기전 준비** <br>\n",
        "CNN 모델을 구성하기 위해서 사전 준비를 한다.   \n",
        "- 먼저 경사하강법을 실행하는 옵티마이저는 SGD로 정한다.\n",
        "- 러닝레이트는 0,01로 한다.\n",
        "- 입력 이미지는 32x32x3 이다."
      ],
      "metadata": {
        "id": "4fUvivY3QNvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "opt = SGD(lr=0.01)\n",
        "\n",
        "height = 32\n",
        "width = 32\n",
        "depth =3\n",
        "\n",
        "model = Sequential()\n",
        "inputShape = (height, width, depth)\n",
        "\n",
        "#이미지 데이터는 일반적으로 3차원 배열로 표현됩니다: 높이(height), 너비(width),  채널(depth)\n",
        "#채널은 이미지의 컬러 채널을 의미하며, 흑백 1, 컬러 이미지 > RGB 채널이므로 3\n",
        "#channels_first: 채널 차원이 배열의 첫 번째 차원으로 오게 됩니다.\n",
        "#따라서 입력 형태는 (채널, 높이, 너비) 순서로 된다\n",
        "#예를 들어 RGB 컬러 이미지의 경우 (3, 높이, 너비) 형태가 됩니다.\n",
        "#channels_last: 이 포맷에서는 채널 차원이 배열의 마지막 차원으로 오게 됩니다.\n",
        "#따라서 입력 형태는 (높이, 너비, 채널) 순서로 되며,\n",
        "#예를 들어 RGB 컬러 이미지의 경우 (높이, 너비, 3) 형태가 됩니다.\n",
        "\n",
        "if K.image_data_format() == \"channels_first\":\n",
        "\n",
        "\tinputShape = (depth, height, width)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WG88qGSJQNeX",
        "outputId": "467c2182-bdb7-4fde-a5cf-5a247071918b"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:`lr` is deprecated in Keras optimizer, please use `learning_rate` or use the legacy optimizer, e.g.,tf.keras.optimizers.legacy.SGD.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#3. 모델의 구성"
      ],
      "metadata": {
        "id": "UbHD4ufSjKGi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "- 1개의 컨볼루션 레이어,\n",
        "- 1개의 댄스레이어(기존 신경망 레이어)\n",
        "- 컨볼루션 레이어의 액티베이션 함수는 relu\n",
        "- 댄스 레이어의 액티베이션 함수는 softmax\n"
      ],
      "metadata": {
        "id": "c_h9BTp3Qx4J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.add(Conv2D(32, (3, 3), padding=\"same\", input_shape=inputShape))\n",
        "model.add(Activation(\"relu\"))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(10))\n",
        "model.add(Activation(\"softmax\"))"
      ],
      "metadata": {
        "id": "hdmDcAzmQ0C5"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델의 구성** <br>\n",
        "옵티마이저, 손실함수, 메트릭을 정해주고 CNN 신경망을 구성한다."
      ],
      "metadata": {
        "id": "aCFqaxxLROI7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(loss=\"categorical_crossentropy\", optimizer=opt, metrics=[\"accuracy\"] )\n"
      ],
      "metadata": {
        "id": "SfDkuqTKRdMW"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#4. 모델 훈련"
      ],
      "metadata": {
        "id": "EG7hOZFGmcxe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**모델 트레이닝** <br>\n",
        "이제 CNN이 구성되었고, trainX, trainY 데이터셋을 이용해서 트레이닝 데이터를 진행한다.   \n",
        "testX testY로 검증을 한다.   \n",
        "총 epochs는 40이다."
      ],
      "metadata": {
        "id": "L_8f9BbyRgAY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "H = model.fit(trainX, trainY, validation_data=(testX, testY), batch_size=32, epochs =40)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "urblFud4Ru0f",
        "outputId": "f81cd9a1-91db-4aa9-c257-65d912023437"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/40\n",
            "1563/1563 [==============================] - 13s 7ms/step - loss: 1.8053 - accuracy: 0.3647 - val_loss: 1.6086 - val_accuracy: 0.4459\n",
            "Epoch 2/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.5214 - accuracy: 0.4689 - val_loss: 1.4548 - val_accuracy: 0.4800\n",
            "Epoch 3/40\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 1.3797 - accuracy: 0.5194 - val_loss: 1.3533 - val_accuracy: 0.5185\n",
            "Epoch 4/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.2987 - accuracy: 0.5493 - val_loss: 1.3351 - val_accuracy: 0.5182\n",
            "Epoch 5/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.2493 - accuracy: 0.5638 - val_loss: 1.3521 - val_accuracy: 0.5202\n",
            "Epoch 6/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.2175 - accuracy: 0.5760 - val_loss: 1.2942 - val_accuracy: 0.5411\n",
            "Epoch 7/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1890 - accuracy: 0.5873 - val_loss: 1.2915 - val_accuracy: 0.5382\n",
            "Epoch 8/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.1626 - accuracy: 0.5955 - val_loss: 1.2601 - val_accuracy: 0.5578\n",
            "Epoch 9/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.1410 - accuracy: 0.6025 - val_loss: 1.2579 - val_accuracy: 0.5532\n",
            "Epoch 10/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 1.1186 - accuracy: 0.6101 - val_loss: 1.2591 - val_accuracy: 0.5503\n",
            "Epoch 11/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0977 - accuracy: 0.6184 - val_loss: 1.2578 - val_accuracy: 0.5543\n",
            "Epoch 12/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0766 - accuracy: 0.6255 - val_loss: 1.2216 - val_accuracy: 0.5720\n",
            "Epoch 13/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0566 - accuracy: 0.6322 - val_loss: 1.2143 - val_accuracy: 0.5768\n",
            "Epoch 14/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 1.0358 - accuracy: 0.6405 - val_loss: 1.2139 - val_accuracy: 0.5766\n",
            "Epoch 15/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0177 - accuracy: 0.6476 - val_loss: 1.2631 - val_accuracy: 0.5663\n",
            "Epoch 16/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 1.0003 - accuracy: 0.6535 - val_loss: 1.2399 - val_accuracy: 0.5740\n",
            "Epoch 17/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9822 - accuracy: 0.6609 - val_loss: 1.2946 - val_accuracy: 0.5572\n",
            "Epoch 18/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9644 - accuracy: 0.6650 - val_loss: 1.2618 - val_accuracy: 0.5589\n",
            "Epoch 19/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.9450 - accuracy: 0.6733 - val_loss: 1.3339 - val_accuracy: 0.5577\n",
            "Epoch 20/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9289 - accuracy: 0.6786 - val_loss: 1.2431 - val_accuracy: 0.5739\n",
            "Epoch 21/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.9119 - accuracy: 0.6841 - val_loss: 1.1885 - val_accuracy: 0.5927\n",
            "Epoch 22/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8926 - accuracy: 0.6928 - val_loss: 1.1949 - val_accuracy: 0.5860\n",
            "Epoch 23/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8795 - accuracy: 0.6988 - val_loss: 1.1989 - val_accuracy: 0.5887\n",
            "Epoch 24/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8626 - accuracy: 0.7025 - val_loss: 1.2041 - val_accuracy: 0.5850\n",
            "Epoch 25/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8460 - accuracy: 0.7090 - val_loss: 1.1527 - val_accuracy: 0.6037\n",
            "Epoch 26/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8317 - accuracy: 0.7154 - val_loss: 1.2763 - val_accuracy: 0.5669\n",
            "Epoch 27/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.8142 - accuracy: 0.7197 - val_loss: 1.3339 - val_accuracy: 0.5581\n",
            "Epoch 28/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.8013 - accuracy: 0.7245 - val_loss: 1.2035 - val_accuracy: 0.5952\n",
            "Epoch 29/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7862 - accuracy: 0.7312 - val_loss: 1.2481 - val_accuracy: 0.5861\n",
            "Epoch 30/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.7738 - accuracy: 0.7338 - val_loss: 1.2652 - val_accuracy: 0.5775\n",
            "Epoch 31/40\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7610 - accuracy: 0.7392 - val_loss: 1.1737 - val_accuracy: 0.6008\n",
            "Epoch 32/40\n",
            "1563/1563 [==============================] - 7s 4ms/step - loss: 0.7461 - accuracy: 0.7437 - val_loss: 1.1970 - val_accuracy: 0.5986\n",
            "Epoch 33/40\n",
            "1563/1563 [==============================] - 9s 5ms/step - loss: 0.7355 - accuracy: 0.7488 - val_loss: 1.1974 - val_accuracy: 0.5974\n",
            "Epoch 34/40\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.7219 - accuracy: 0.7518 - val_loss: 1.1902 - val_accuracy: 0.6088\n",
            "Epoch 35/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.7083 - accuracy: 0.7563 - val_loss: 1.2245 - val_accuracy: 0.5950\n",
            "Epoch 36/40\n",
            "1563/1563 [==============================] - 9s 6ms/step - loss: 0.6972 - accuracy: 0.7599 - val_loss: 1.2919 - val_accuracy: 0.5806\n",
            "Epoch 37/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6854 - accuracy: 0.7640 - val_loss: 1.2061 - val_accuracy: 0.6028\n",
            "Epoch 38/40\n",
            "1563/1563 [==============================] - 6s 4ms/step - loss: 0.6760 - accuracy: 0.7695 - val_loss: 1.2052 - val_accuracy: 0.6034\n",
            "Epoch 39/40\n",
            "1563/1563 [==============================] - 8s 5ms/step - loss: 0.6633 - accuracy: 0.7753 - val_loss: 1.2329 - val_accuracy: 0.5997\n",
            "Epoch 40/40\n",
            "1563/1563 [==============================] - 7s 5ms/step - loss: 0.6523 - accuracy: 0.7784 - val_loss: 1.2361 - val_accuracy: 0.6009\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#5. 예측"
      ],
      "metadata": {
        "id": "yU2ILJfrnOqF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**트레이닝 결과 확인하기** <br>\n",
        "트레이닝 한 결과를 확인한다.   \n",
        "실제로 CIFAR10 데이터셋은 CNN을 사용해도 예측률이 60%정도로 그리 좋지는 않다.  \n",
        "\n",
        "* 데이터셋의 해상도가 너무 낮고 데이터숫자가 많지 않아서 발생하는 현상이다."
      ],
      "metadata": {
        "id": "MlvRVMfxSAyT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = model.predict(testX, batch_size=32)\n",
        "print(classification_report(testY.argmax(axis=1),\n",
        "\tpredictions.argmax(axis=1), target_names=labelNames))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Va560YiUTcbB",
        "outputId": "aa7b17a2-0210-470c-f5d1-c8dcb94b126e"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 1s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "    airplane       0.69      0.63      0.66      1000\n",
            "  automobile       0.78      0.66      0.72      1000\n",
            "        bird       0.48      0.40      0.44      1000\n",
            "         cat       0.40      0.49      0.44      1000\n",
            "        deer       0.45      0.64      0.53      1000\n",
            "         dog       0.52      0.47      0.50      1000\n",
            "        frog       0.80      0.59      0.68      1000\n",
            "       horse       0.66      0.68      0.67      1000\n",
            "        ship       0.78      0.69      0.73      1000\n",
            "       truck       0.63      0.75      0.68      1000\n",
            "\n",
            "    accuracy                           0.60     10000\n",
            "   macro avg       0.62      0.60      0.60     10000\n",
            "weighted avg       0.62      0.60      0.60     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#6. 추론 파일 저장"
      ],
      "metadata": {
        "id": "6Kts7KnhnZki"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**CNN 추론파일 저장하기** <br>\n",
        "트레이닝된 추론파일을 다음에 사용하기 위해서 디스크에 저장한다.\n",
        "\n",
        "생성된 H5 파일을 로컬에 저장한다"
      ],
      "metadata": {
        "id": "yHeYut30UAGI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('cifar10_cnn.h5')"
      ],
      "metadata": {
        "id": "y8XzrKLmUAvC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e56e104-84b5-4feb-a09b-249ad5bf7d24"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/keras/src/engine/training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
            "  saving_api.save_model(\n"
          ]
        }
      ]
    }
  ]
}
