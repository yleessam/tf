{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yleessam/tf/blob/main/MLP_XOR_%EB%B0%B0%ED%8F%AC.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# numpy 임포트"
      ],
      "metadata": {
        "id": "ElfZHBpGku-Y"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X5bqNLhYkUeo"
      },
      "outputs": [],
      "source": [
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다층 퍼셉트론 클래스"
      ],
      "metadata": {
        "id": "FCEREn_1k5ml"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class NeuralNetwork:\n",
        "\n",
        "    def __init__(self, layers, alpha=0.1):\n",
        "        # 생성자: 신경망 초기화\n",
        "        # alpha: 학습률\n",
        "        self.W = [] # 가중치를 저장할 리스트\n",
        "\n",
        "        self.layers = layers  # list [ 2, 2, 2, 1]\n",
        "        self.alpha = alpha\n",
        "\n",
        "        # 가중치 초기화: 입력 레이어부터 마지막 은닉 레이어까지의 가중치를 초기화\n",
        "        for i in np.arange(0, len(layers) - 2):\n",
        "\n",
        "        # 마지막 은닉층에서 출력층으로의 가중치를 초기화합니다., 마지막 hidden - out 사이의 계수\n",
        "\n",
        "\n",
        "    def sigmoid(self, x):\n",
        "        # 시그모이드 활성화 함수: 신경망의 각 노드에서 사용\n",
        "        return\n",
        "\n",
        "    def sigmoid_deriv(self, x):\n",
        "        # 시그모이드 활성화 함수의 미분: 이는 역전파 시 그래디언트(기울기)를 계산할 때 사용\n",
        "        return\n",
        "\n",
        "    # 신경망을 학습시키는 메서드입니다.\n",
        "    # 입력 X = np.array([[ 0,0], [ 0,1], [1,0], [0,0]])\n",
        "    # 타겟 y = np.array([[0], [1], [1], [0]])\n",
        "    # epochs: 학습을 위해 데이터셋을 반복할 횟수입니다.\n",
        "    def fit(self, X, y, epochs=1000):\n",
        "        # 입력 데이터에 바이어스를 위한 1 추가\n",
        "\n",
        "\n",
        "    def fit_partial(self, x, y):\n",
        "        # 부분 학습 메서드: x는 단일 데이터 샘플, y는 해당 타겟 레이블\n",
        "        A =\n",
        "        # 순전파 단계: 입력 데이터가 네트워크를 통해 전파되면서 각 레이어의 출력 계산\n",
        "\n",
        "\n",
        "        # 역전파 단계: 신경망의 출력과 실제 타겟 값의 차이를 계산합니다.\n",
        "\n",
        "        # 오류의 시그모이드 미분값을 사용하여 오류 신호 계산\n",
        "        D =\n",
        "        # 모든 층에 대해 역전파를 수행합니다. 출력층부터 시작하여 입력층 방향으로 진행합니다.\n",
        "\n",
        "\n",
        "        # D 리스트를 뒤집습니다. 이렇게 하여 입력층에 가까운 오류부터 시작하게 됩니다.\n",
        "        D =\n",
        "        # 가중치 업데이트: 모든 레이어에 대해 가중치를 업데이트합니다.\n",
        "\n",
        "\n",
        "    # 예측 메서드: 새로운 데이터에 대한 예측을 수행합니다.\n",
        "    def predict(self, X):  # X = [0 1]\n",
        "        # 입력 데이터를 최소 2차원 배열로 변환합니다.\n",
        "        p =\n",
        "\n",
        "        # 바이어스를 위한 1을 추가합니다.\n",
        "        p =\n",
        "\n",
        "        # 신경망을 통해 순전파를 수행하여 예측 결과를 계산합니다.\n",
        "        for layer in np.arange(0, len(self.W)):\n",
        "            p =\n",
        "        return p"
      ],
      "metadata": {
        "id": "yBSseZxYkxxz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 다층 퍼셉트론 클래스 객체 생성,\n",
        "\n",
        "1 hidden layer, learning rate 0.5"
      ],
      "metadata": {
        "id": "k1cJfQjAlBYM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "nn = NeuralNetwork([2, 2, 1], 0.5)"
      ],
      "metadata": {
        "id": "1aLUUj05k83o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# XOR 입력 데이터 정의, 출력값 정의, 트레이닝(back-propagation)"
      ],
      "metadata": {
        "id": "GDwXPRyKlVCx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "X = np.array([[ 0,0], [ 0,1], [1,0], [1,1]])\n",
        "y = np.array([[0], [1], [1], [0]])\n"
      ],
      "metadata": {
        "id": "M8cTBvxWlR24"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# feed-forward 예측"
      ],
      "metadata": {
        "id": "BoFZxCF2le1Z"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "A1RpHkpblbBB"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
