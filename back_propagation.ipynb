{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yleessam/tf/blob/main/back_propagation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 단일노드 퍼셉트론\n",
        "\n",
        "백프로퍼게이션 클래스 추가"
      ],
      "metadata": {
        "id": "GWkZDOl9hy3d"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "q1wwtlSjhmSy"
      },
      "outputs": [],
      "source": [
        "class Neuron:\n",
        "    def __init__(self, w, b):\n",
        "        # 생성자에서는 가중치(w)와 바이어스(b)를 초기화합니다.\n",
        "        self.w = w\n",
        "        self.b = b\n",
        "\n",
        "    # 순전파\n",
        "    def feedForward(self, input):\n",
        "\n",
        "        # output y = f(\\sigma)\n",
        "        # \\sigma = w * input x + b\n",
        "        # for multiple inputs,\n",
        "        # \\sigma = w0 * input x0 + w1 * input x1 + ... + b\n",
        "\n",
        "        sigma = self.w * input + self.b\n",
        "        output = self.getActivation(sigma) # 활성화 함수를 적용하여 뉴런의 출력을 계산\n",
        "\n",
        "        # 입력과 출력을 객체 내부 변수로 저장합니다.\n",
        "        # 이는 나중에 역전파 시 사용됩니다.\n",
        "        self.input = input # 입력 값\n",
        "        self.output = output  # 활성화 함수를 거친 후의 출력 값\n",
        "\n",
        "        return output\n",
        "\n",
        "    # 활성화 함수를 정의하는 메서드입니다.\n",
        "    # 현재는 선형 활성화 함수(즉, 입력을 그대로 출력)를 사용합니다.\n",
        "    def getActivation(self, x):\n",
        "        # for linear or identity activation function\n",
        "        return x\n",
        "\n",
        "        # for ReLU activation function\n",
        "        # return max([0.0, x])\n",
        "\n",
        "    # 활성화 함수의 그래디언트(미분값)를 반환하는 메서드입니다.\n",
        "    # 현재는 선형 활성화 함수의 그래디언트(항상 1)를 반환합니다.\n",
        "    def getActGrad(self, x):\n",
        "        # for linear or identity activation function\n",
        "        return 1.0\n",
        "\n",
        "        # for ReLU\n",
        "        # if x > 0.0: return x\n",
        "        # else: return 0.0\n",
        "\n",
        "    # 역전파 메서드: 출력과 타겟 값 사이의 오차를 바탕으로 가중치와 바이어스를 업데이트합니다.\n",
        "    def propBackward(self, target):\n",
        "\n",
        "        # 학습률(alpha)는 가중치 업데이트 시 적용하는 스텝 크기를 결정\n",
        "        a = 0.1\n",
        "\n",
        "         # 오차를 계산합니다.\n",
        "        error = self.output - target\n",
        "\n",
        "        # 활성화 함수의 그래디언트와 입력을 곱한 값으로 가중치를 업데이트합니다.\n",
        "        self.w = self.w - a * error * self.getActGrad(self.output) * self.input\n",
        "\n",
        "        # 활성화 함수의 그래디언트로 바이어스를 업데이트합니다.\n",
        "        self.b = self.b - a * error * self.getActGrad(self.output)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "백프로퍼게이션 객체 생성. 계수 W 2.0 바이어스 b 1.0"
      ],
      "metadata": {
        "id": "qrX5JXKXh_jA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "neuron = Neuron(2.0, 1.0)"
      ],
      "metadata": {
        "id": "vLg_MApMh7Gz"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "백프로퍼게이션 진행"
      ],
      "metadata": {
        "id": "81atyjhriUgz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 100번의 반복 학습(epoch)을 수행합니다.\n",
        "for unused in range(1, 100):\n",
        "    # 순전파 과정을 통해 입력값 1.0에 대한 뉴런의 출력을 계산합니다.\n",
        "    # feedForward 메서드는 뉴런의 출력을 반환합니다.\n",
        "    # 여기서 출력값은 현재 가중치와 바이어스를 사용하여 계산된 값입니다.\n",
        "\n",
        "    print('Input 1.0 -> Output {}'.format(neuron.feedForward(1.0)))\n",
        "\n",
        "    # 역전파 과정을 통해 뉴런의 가중치와 바이어스를 업데이트합니다.\n",
        "\n",
        "    # propBackward 메서드는 목표값(target) 4.0 > output 출력값 >> 을 인자로 받아 현재 출력과의 오차를 바탕으로\n",
        "    # 학습률과 그래디언트를 사용하여 가중치와 바이어스를 조정합니다.\n",
        "    # 이 과정은 뉴런의 출력이 목표값에 가까워지도록 합니다.\n",
        "\n",
        "    neuron.propBackward(4.0)"
      ],
      "metadata": {
        "id": "K5mowuDuiHuy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "315ff939-c8a2-4f70-ec76-945fecffe9dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input 1.0 -> Output 3.0\n",
            "Input 1.0 -> Output 3.2\n",
            "Input 1.0 -> Output 3.3600000000000003\n",
            "Input 1.0 -> Output 3.4880000000000004\n",
            "Input 1.0 -> Output 3.5904000000000007\n",
            "Input 1.0 -> Output 3.6723200000000005\n",
            "Input 1.0 -> Output 3.7378560000000003\n",
            "Input 1.0 -> Output 3.7902848000000002\n",
            "Input 1.0 -> Output 3.83222784\n",
            "Input 1.0 -> Output 3.8657822719999997\n",
            "Input 1.0 -> Output 3.8926258176\n",
            "Input 1.0 -> Output 3.9141006540800003\n",
            "Input 1.0 -> Output 3.9312805232640002\n",
            "Input 1.0 -> Output 3.9450244186112\n",
            "Input 1.0 -> Output 3.95601953488896\n",
            "Input 1.0 -> Output 3.964815627911168\n",
            "Input 1.0 -> Output 3.971852502328934\n",
            "Input 1.0 -> Output 3.977482001863147\n",
            "Input 1.0 -> Output 3.9819856014905177\n",
            "Input 1.0 -> Output 3.985588481192414\n",
            "Input 1.0 -> Output 3.988470784953931\n",
            "Input 1.0 -> Output 3.990776627963145\n",
            "Input 1.0 -> Output 3.992621302370516\n",
            "Input 1.0 -> Output 3.9940970418964126\n",
            "Input 1.0 -> Output 3.99527763351713\n",
            "Input 1.0 -> Output 3.996222106813704\n",
            "Input 1.0 -> Output 3.9969776854509633\n",
            "Input 1.0 -> Output 3.9975821483607707\n",
            "Input 1.0 -> Output 3.9980657186886166\n",
            "Input 1.0 -> Output 3.9984525749508935\n",
            "Input 1.0 -> Output 3.9987620599607148\n",
            "Input 1.0 -> Output 3.999009647968572\n",
            "Input 1.0 -> Output 3.9992077183748576\n",
            "Input 1.0 -> Output 3.999366174699886\n",
            "Input 1.0 -> Output 3.999492939759909\n",
            "Input 1.0 -> Output 3.999594351807927\n",
            "Input 1.0 -> Output 3.9996754814463413\n",
            "Input 1.0 -> Output 3.9997403851570734\n",
            "Input 1.0 -> Output 3.9997923081256586\n",
            "Input 1.0 -> Output 3.9998338465005268\n",
            "Input 1.0 -> Output 3.9998670772004212\n",
            "Input 1.0 -> Output 3.9998936617603373\n",
            "Input 1.0 -> Output 3.99991492940827\n",
            "Input 1.0 -> Output 3.999931943526616\n",
            "Input 1.0 -> Output 3.999945554821293\n",
            "Input 1.0 -> Output 3.9999564438570347\n",
            "Input 1.0 -> Output 3.9999651550856274\n",
            "Input 1.0 -> Output 3.9999721240685018\n",
            "Input 1.0 -> Output 3.999977699254801\n",
            "Input 1.0 -> Output 3.999982159403841\n",
            "Input 1.0 -> Output 3.9999857275230726\n",
            "Input 1.0 -> Output 3.9999885820184584\n",
            "Input 1.0 -> Output 3.999990865614767\n",
            "Input 1.0 -> Output 3.999992692491814\n",
            "Input 1.0 -> Output 3.999994153993451\n",
            "Input 1.0 -> Output 3.999995323194761\n",
            "Input 1.0 -> Output 3.9999962585558086\n",
            "Input 1.0 -> Output 3.999997006844647\n",
            "Input 1.0 -> Output 3.9999976054757176\n",
            "Input 1.0 -> Output 3.9999980843805742\n",
            "Input 1.0 -> Output 3.9999984675044593\n",
            "Input 1.0 -> Output 3.9999987740035676\n",
            "Input 1.0 -> Output 3.9999990192028543\n",
            "Input 1.0 -> Output 3.9999992153622834\n",
            "Input 1.0 -> Output 3.9999993722898264\n",
            "Input 1.0 -> Output 3.999999497831861\n",
            "Input 1.0 -> Output 3.9999995982654886\n",
            "Input 1.0 -> Output 3.999999678612391\n",
            "Input 1.0 -> Output 3.999999742889913\n",
            "Input 1.0 -> Output 3.9999997943119308\n",
            "Input 1.0 -> Output 3.9999998354495445\n",
            "Input 1.0 -> Output 3.9999998683596356\n",
            "Input 1.0 -> Output 3.9999998946877087\n",
            "Input 1.0 -> Output 3.999999915750167\n",
            "Input 1.0 -> Output 3.999999932600134\n",
            "Input 1.0 -> Output 3.9999999460801074\n",
            "Input 1.0 -> Output 3.9999999568640856\n",
            "Input 1.0 -> Output 3.9999999654912686\n",
            "Input 1.0 -> Output 3.999999972393015\n",
            "Input 1.0 -> Output 3.999999977914412\n",
            "Input 1.0 -> Output 3.9999999823315298\n",
            "Input 1.0 -> Output 3.999999985865224\n",
            "Input 1.0 -> Output 3.999999988692179\n",
            "Input 1.0 -> Output 3.9999999909537434\n",
            "Input 1.0 -> Output 3.999999992762995\n",
            "Input 1.0 -> Output 3.9999999942103956\n",
            "Input 1.0 -> Output 3.9999999953683165\n",
            "Input 1.0 -> Output 3.9999999962946533\n",
            "Input 1.0 -> Output 3.9999999970357227\n",
            "Input 1.0 -> Output 3.9999999976285783\n",
            "Input 1.0 -> Output 3.9999999981028624\n",
            "Input 1.0 -> Output 3.99999999848229\n",
            "Input 1.0 -> Output 3.999999998785832\n",
            "Input 1.0 -> Output 3.999999999028666\n",
            "Input 1.0 -> Output 3.9999999992229327\n",
            "Input 1.0 -> Output 3.999999999378346\n",
            "Input 1.0 -> Output 3.999999999502677\n",
            "Input 1.0 -> Output 3.9999999996021414\n",
            "Input 1.0 -> Output 3.9999999996817133\n"
          ]
        }
      ]
    }
  ]
}